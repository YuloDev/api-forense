"""
Helper para anÃ¡lisis de evidencias forenses.

Utiliza la misma lÃ³gica que el helper existente en analisis_forense_profesional.py
"""

from typing import Dict, Any, List
from adapters.persistence.helpers.ForensicAnalysisHelpers.check_evidencias_forenses.forensic_analysis_imports import (
    analizar_metadatos_forenses,
    detectar_texto_sintetico_aplanado,
    detectar_texto_sobrepuesto,
    safe_serialize_dict
)


class EvidenciasForensesAnalyzer:
    """Analizador de evidencias forenses usando la lÃ³gica existente del proyecto"""
    
    def __init__(self):
        pass
    
    def analyze_image_evidencias_forenses(self, image_bytes: bytes) -> Dict[str, Any]:
        """
        Analiza evidencias forenses en una imagen usando la lÃ³gica existente.
        
        Args:
            image_bytes: Bytes del archivo de imagen
            
        Returns:
            Dict con anÃ¡lisis de evidencias forenses
        """
        try:
            # Usar la funciÃ³n existente del helper
            result = self._analisis_forense_completo(image_bytes)
            
            return result
            
        except Exception as e:
            return {
                "error": f"Error analizando evidencias forenses: {str(e)}",
                "evidencias": [],
                "grado_confianza": "ERROR",
                "porcentaje_confianza": 0.0,
                "puntuacion": 0,
                "max_puntuacion": 0,
                "es_screenshot": False,
                "tipo_imagen": "unknown"
            }
    
    def _analisis_forense_completo(self, imagen_bytes: bytes) -> Dict[str, Any]:
        """
        FunciÃ³n idÃ©ntica a analisis_forense_completo del helper original.
        AnÃ¡lisis forense ULTRA-OPTIMIZADO para velocidad.
        """
        try:
            # Solo anÃ¡lisis mÃ¡s importantes y rÃ¡pidos
            metadatos = analizar_metadatos_forenses(imagen_bytes)
            
            # AnÃ¡lisis de texto sintÃ©tico (importante mantener)
            texto_sintetico = detectar_texto_sintetico_aplanado(imagen_bytes, metadatos)
            
            # AnÃ¡lisis simplificados para velocidad
            compresion = {"doble_compresion": {"tiene_doble_compresion": False}}
            cuadricula_jpeg = {"tiene_cuadricula": False}
            ela = {"tiene_ediciones": False}
            ruido_bordes = {"ruido_analisis": {"inconsistencias_ruido": ""}}
            hashes = {"inconsistencias": []}
            
            # ðŸ”Ž Detector de texto sobrepuesto (ya optimizado)
            overlays = detectar_texto_sobrepuesto(imagen_bytes)
            n_over = overlays.get("resumen", {}).get("n_overlays", 0)
            
            # Generar reporte consolidado
            evidencias = []
            puntuacion = 0
            max_puntuacion = 0
            
            # AnÃ¡lisis de metadatos
            if metadatos.get("software_edicion"):
                for evidencia in metadatos["software_edicion"]:
                    if "ðŸš¨" in evidencia:
                        evidencias.append(evidencia)
                        puntuacion += 3
                    else:
                        evidencias.append(evidencia)
                        puntuacion += 1
            max_puntuacion += 5
            
            # AnÃ¡lisis de fechas
            if metadatos.get("fechas_analisis"):
                for evidencia in metadatos["fechas_analisis"]:
                    if "ðŸš¨" in evidencia:
                        evidencias.append(evidencia)
                        puntuacion += 3
                    else:
                        evidencias.append(evidencia)
                        puntuacion += 1
            max_puntuacion += 3
            
            # AnÃ¡lisis de compresiÃ³n
            if compresion.get("app_indicators"):
                for evidencia in compresion["app_indicators"]:
                    if "ðŸš¨" in evidencia:
                        evidencias.append(evidencia)
                        puntuacion += 2
            max_puntuacion += 2
            
            # AnÃ¡lisis de cuadrÃ­cula JPEG
            if cuadricula_jpeg.get("tiene_splicing"):
                evidencias.append("ðŸš¨ CUADRÃCULA JPEG LOCALIZADA - POSIBLE SPLICING")
                puntuacion += 4
            elif cuadricula_jpeg.get("desalineacion_analisis", {}).get("total_discontinuidades", 0) > 2:
                evidencias.append("âš ï¸ DesalineaciÃ³n de bloques JPEG detectada")
                puntuacion += 2
            max_puntuacion += 4
            
            # AnÃ¡lisis de texto sintÃ©tico aplanado
            # AnÃ¡lisis de texto sintÃ©tico (lÃ³gica mejorada)
            es_screenshot = texto_sintetico.get("tipo_imagen_analisis", {}).get("es_screenshot", False)
            
            if texto_sintetico.get("tiene_texto_sintetico"):
                if es_screenshot:
                    evidencias.append("âš ï¸ Texto sintÃ©tico en screenshot/web")
                    puntuacion += 2  # Menos penalizaciÃ³n para screenshots
                else:
                    evidencias.append("ðŸš¨ TEXTO SINTÃ‰TICO APLANADO DETECTADO")
                    puntuacion += 5
            elif texto_sintetico.get("reguardado_analisis", {}).get("densidad_lineas", 0) > 0.15:  # Umbral mÃ¡s alto
                if es_screenshot:
                    evidencias.append("â„¹ï¸ Alta densidad de lÃ­neas (screenshot)")
                    puntuacion += 0  # No penalizar screenshots
                else:
                    evidencias.append("âš ï¸ Alta densidad de lÃ­neas rectilÃ­neas")
                    puntuacion += 2
            elif texto_sintetico.get("swt_analisis", {}).get("stroke_width_uniforme", False):
                if es_screenshot:
                    evidencias.append("â„¹ï¸ Grosor uniforme (screenshot)")
                    puntuacion += 0  # No penalizar screenshots
                else:
                    evidencias.append("âš ï¸ Grosor de trazo uniforme (texto sintÃ©tico)")
                    puntuacion += 2
            max_puntuacion += 5
            
            # AnÃ¡lisis ELA (requerir evidencia localizada)
            if ela.get("tiene_ediciones"):
                if ela.get("nivel_sospecha") == "ALTO":
                    evidencias.append(f"ðŸš¨ ELA detectÃ³ ediciones significativas (nivel: {ela.get('nivel_sospecha', 'N/A')})")
                    puntuacion += 3
                elif ela.get("nivel_sospecha") == "MEDIO":
                    # Solo penalizar si hay evidencia localizada
                    if cuadricula_jpeg.get("tiene_splicing") or texto_sintetico.get("tiene_texto_sintetico"):
                        evidencias.append(f"âš ï¸ ELA detectÃ³ ediciones + evidencia localizada (nivel: {ela.get('nivel_sospecha', 'N/A')})")
                        puntuacion += 2
                    else:
                        evidencias.append(f"â„¹ï¸ ELA detectÃ³ ediciones menores (posible compresiÃ³n)")
                        puntuacion += 0  # No penalizar compresiÃ³n normal
                else:
                    evidencias.append(f"â„¹ï¸ ELA detectÃ³ ediciones menores (posible compresiÃ³n)")
                    puntuacion += 0  # No penalizar compresiÃ³n normal
            max_puntuacion += 3
            
            # AnÃ¡lisis de ruido y bordes (solo si hay evidencia localizada)
            if ruido_bordes.get("ruido_analisis", {}).get("inconsistencias_ruido", "").startswith("ðŸš¨"):
                if cuadricula_jpeg.get("tiene_splicing") or texto_sintetico.get("tiene_texto_sintetico"):
                    evidencias.append("ðŸš¨ Inconsistencias de ruido + evidencia localizada")
                    puntuacion += 2
                else:
                    evidencias.append("â„¹ï¸ Inconsistencias de ruido (posible compresiÃ³n)")
                    puntuacion += 0  # No penalizar compresiÃ³n normal
            max_puntuacion += 2
            
            if ruido_bordes.get("halo_analisis", {}).get("halo_detectado", "").startswith("ðŸš¨"):
                if cuadricula_jpeg.get("tiene_splicing") or texto_sintetico.get("tiene_texto_sintetico"):
                    evidencias.append("ðŸš¨ Halo/aliasing + evidencia localizada")
                    puntuacion += 2
                else:
                    evidencias.append("â„¹ï¸ Halo/aliasing (posible compresiÃ³n)")
                    puntuacion += 0  # No penalizar compresiÃ³n normal
            max_puntuacion += 2
            
            # AnÃ¡lisis de hashes
            if hashes.get("inconsistencias"):
                for evidencia in hashes["inconsistencias"]:
                    evidencias.append(evidencia)
                    puntuacion += 1
            max_puntuacion += 2
            
            # ðŸ”Ž Sumar evidencia por texto sobrepuesto
            if n_over > 0:
                evidencias.append(f"ðŸš¨ Texto sobrepuesto detectado en {n_over} caja(s) OCR")
                puntuacion += min(5, 2 + n_over)  # pesa de 2 a 5
            max_puntuacion += 5
            
            # Calcular grado de confianza (ajustado para screenshots)
            porcentaje_confianza = (puntuacion / max_puntuacion) * 100 if max_puntuacion > 0 else 0
            
            # Ajustar para screenshots
            if es_screenshot and porcentaje_confianza < 30:
                grado_confianza = "BAJO"
                evidencias.append("â„¹ï¸ Imagen parece ser screenshot/web (recomprimida)")
            elif porcentaje_confianza > 70:
                grado_confianza = "ALTO"
            elif porcentaje_confianza > 40:
                grado_confianza = "MEDIO"
            else:
                grado_confianza = "BAJO"
            
            return safe_serialize_dict({
                "metadatos": metadatos,
                "compresion": compresion,
                "cuadricula_jpeg": cuadricula_jpeg,
                "texto_sintetico": texto_sintetico,
                "ela": ela,
                "ruido_bordes": ruido_bordes,
                "hashes": hashes,
                "overlays": overlays,  # ðŸ”Ž incluir resultados nuevos
                "evidencias": evidencias,
                "grado_confianza": grado_confianza,
                "porcentaje_confianza": float(porcentaje_confianza),
                "puntuacion": puntuacion,
                "max_puntuacion": max_puntuacion,
                "es_screenshot": es_screenshot,
                "tipo_imagen": "screenshot/web" if es_screenshot else "imagen_normal"
            })
            
        except Exception as e:
            return {
                "error": f"Error en anÃ¡lisis forense completo: {str(e)}",
                "evidencias": [],
                "grado_confianza": "ERROR",
                "porcentaje_confianza": 0.0
            }
